{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first NLP exercise is about preprocessing.\n",
    "\n",
    "You will practice preprocessing using NLTK on raw data. \n",
    "This is the first step in most of the NLP projects, so you have to master it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will play with the *coldplay.csv* dataset, containing all the songs and lyrics of Coldplay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\natha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\natha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\natha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\natha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK and all the needed libraries\n",
    "import nltk\n",
    "nltk.download('punkt') #Run this line one time to get the resource\n",
    "nltk.download('stopwords') #Run this line one time to get the resource\n",
    "nltk.download('wordnet') #Run this line one time to get the resource\n",
    "nltk.download('averaged_perceptron_tagger') #Run this line one time to get the resource\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Link</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Another's Arms</td>\n",
       "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
       "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Bigger Stronger</td>\n",
       "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
       "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>/c/coldplay/daylight_20032625.html</td>\n",
       "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Everglow</td>\n",
       "      <td>/c/coldplay/everglow_21104546.html</td>\n",
       "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Every Teardrop Is A Waterfall</td>\n",
       "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
       "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Artist                           Song  \\\n",
       "0  Coldplay                 Another's Arms   \n",
       "1  Coldplay                Bigger Stronger   \n",
       "2  Coldplay                       Daylight   \n",
       "3  Coldplay                       Everglow   \n",
       "4  Coldplay  Every Teardrop Is A Waterfall   \n",
       "\n",
       "                                                Link  \\\n",
       "0            /c/coldplay/anothers+arms_21079526.html   \n",
       "1          /c/coldplay/bigger+stronger_20032648.html   \n",
       "2                 /c/coldplay/daylight_20032625.html   \n",
       "3                 /c/coldplay/everglow_21104546.html   \n",
       "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  Late night watching tv  \\nUsed to be you here ...  \n",
       "1  I want to be bigger stronger drive a faster ca...  \n",
       "2  To my surprise, and my delight  \\nI saw sunris...  \n",
       "3  Oh, they say people come  \\nThey say people go...  \n",
       "4  I turn the music up, I got my records on  \\nI ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset in coldplay.csv\n",
    "df = pd.read_csv('coldplay.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the dataset, play with it a bit: what are the columns? How many lines? Is there missing data?..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Artist  120 non-null    object\n",
      " 1   Song    120 non-null    object\n",
      " 2   Link    120 non-null    object\n",
      " 3   Lyrics  120 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select the song 'Every Teardrop Is A Waterfall' and save the Lyrics text into a variable. Print the output of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select the song 'Every Teardrop Is A Waterfall'\n",
    "s = df.loc[df[\"Song\"] == \"Every Teardrop Is A Waterfall\"].values[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is some preprocessing needed here. So let's do it! What is usually the first step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, yes. So do tokenization on the lyrics of Every Teardrop Is A Waterfall.\n",
    "\n",
    "So you may have to import the needed library from NLTK if you did not yet.\n",
    "\n",
    "Be careful, the output you have from your pandas dataframe may not have the right type, so manipulate it wisely to get a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'alight',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'trees',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'dance',\n",
       " ',',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'this',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'is',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'on',\n",
       " 'my',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'beating',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'this',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " ',',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'alright',\n",
       " 'As',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'walls',\n",
       " ',',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'is',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " ',',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " \"'ll\",\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa-aterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa-aterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Tokenize the lyrics of the song and save the tokens into a variable and print it\n",
    "token = nltk.word_tokenize(s)\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It begins to look good. But still, we have the punctuation to remove, so let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'trees',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'dance',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'this',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'is',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Dont',\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'Id',\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'my',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'beating',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'this',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'its',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'walls',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'is',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tears',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'Ill',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Remove the punctuation, then save the result into a variable and print it\n",
    "import string\n",
    "s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "token = nltk.word_tokenize(s)\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'records',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'Maybe',\n",
       " 'streets',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'trees',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'kids',\n",
       " 'dance',\n",
       " 'kids',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'Im',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'records',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Dont',\n",
       " 'want',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'Id',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'Im',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'heart',\n",
       " 'beating',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'soar',\n",
       " 'walls',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tears',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'Ill',\n",
       " 'raise',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove the stop words using NLTK. Then put the result into a variable and print it\n",
    "\n",
    "token = [x for x in token if x not in nltk.corpus.stopwords.words('english')]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we begin to have much less words in our song, right?\n",
    "\n",
    "Next step is lemmatization. But we had an issue in the lectures, you remember? Let's learn how to do it properly now.\n",
    "\n",
    "First let's try to do it naively. Import the WordNetLemmatizer and perform lemmatization with default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'record',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'light',\n",
       " 'come',\n",
       " 'Maybe',\n",
       " 'street',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'tree',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'kid',\n",
       " 'dance',\n",
       " 'kid',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feel',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'Im',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'I',\n",
       " 'got',\n",
       " 'record',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Dont',\n",
       " 'want',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'Id',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'Im',\n",
       " 'knee',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapeze',\n",
       " 'But',\n",
       " 'heart',\n",
       " 'beating',\n",
       " 'pulse',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'soar',\n",
       " 'wall',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'Ill',\n",
       " 'raise',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform lemmatization using WordNetLemmatizer on our tokens\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "token = [lemma.lemmatize(x) for x in token]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it worked well on nouns (plural words are now singular for example).\n",
    "\n",
    "But verbs are not OK: we would 'is' to become 'be' for example.\n",
    "\n",
    "To do that, we need to do POS-tagging. So let's do this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS-tagging means Part of speech tagging: basically it will classify words into categories: like verbs, nouns, advers and so on...\n",
    "\n",
    "In order to do that, we will use NLTK and the function *pos_tag*. You have to do it on the step before lemmatization, so use your variable containing all the tokens without punctuation and without stop words.\n",
    "\n",
    "Hint: you can check on the internet how the *pos_tag* function works [here](https://www.nltk.org/book/ch05.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('turn', 'VBP'),\n",
       " ('music', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('record', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('shut', 'VBP'),\n",
       " ('world', 'NN'),\n",
       " ('outside', 'IN'),\n",
       " ('light', 'JJ'),\n",
       " ('come', 'VBP'),\n",
       " ('Maybe', 'NNP'),\n",
       " ('street', 'NN'),\n",
       " ('alight', 'VBD'),\n",
       " ('maybe', 'RB'),\n",
       " ('tree', 'JJ'),\n",
       " ('gone', 'VBN'),\n",
       " ('I', 'PRP'),\n",
       " ('feel', 'VBP'),\n",
       " ('heart', 'NN'),\n",
       " ('start', 'NN'),\n",
       " ('beating', 'VBG'),\n",
       " ('favourite', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('kid', 'NN'),\n",
       " ('dance', 'NN'),\n",
       " ('kid', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('Until', 'IN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('morning', 'NN'),\n",
       " ('feel', 'NN'),\n",
       " ('another', 'DT'),\n",
       " ('life', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('turn', 'VBP'),\n",
       " ('music', 'NN'),\n",
       " ('Im', 'NNP'),\n",
       " ('roll', 'NN'),\n",
       " ('time', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('heaven', 'JJ'),\n",
       " ('sight', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('turn', 'VBP'),\n",
       " ('music', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('got', 'VBD'),\n",
       " ('record', 'NN'),\n",
       " ('From', 'IN'),\n",
       " ('underneath', 'JJ'),\n",
       " ('rubble', 'JJ'),\n",
       " ('sing', 'VBG'),\n",
       " ('rebel', 'NN'),\n",
       " ('song', 'NN'),\n",
       " ('Dont', 'NNP'),\n",
       " ('want', 'NN'),\n",
       " ('see', 'NN'),\n",
       " ('another', 'DT'),\n",
       " ('generation', 'NN'),\n",
       " ('drop', 'NN'),\n",
       " ('Id', 'NNP'),\n",
       " ('rather', 'RB'),\n",
       " ('comma', 'VBZ'),\n",
       " ('full', 'JJ'),\n",
       " ('stop', 'NN'),\n",
       " ('Maybe', 'NNP'),\n",
       " ('Im', 'NNP'),\n",
       " ('black', 'JJ'),\n",
       " ('maybe', 'RB'),\n",
       " ('Im', 'NNP'),\n",
       " ('knee', 'NN'),\n",
       " ('Maybe', 'NNP'),\n",
       " ('Im', 'NNP'),\n",
       " ('gap', 'NN'),\n",
       " ('two', 'CD'),\n",
       " ('trapeze', 'NN'),\n",
       " ('But', 'CC'),\n",
       " ('heart', 'NN'),\n",
       " ('beating', 'NN'),\n",
       " ('pulse', 'JJ'),\n",
       " ('start', 'NN'),\n",
       " ('Cathedrals', 'NNP'),\n",
       " ('heart', 'NN'),\n",
       " ('As', 'IN'),\n",
       " ('saw', 'JJ'),\n",
       " ('oh', 'IN'),\n",
       " ('light', 'JJ'),\n",
       " ('I', 'PRP'),\n",
       " ('swear', 'VBP'),\n",
       " ('emerge', 'RB'),\n",
       " ('blinking', 'VBG'),\n",
       " ('To', 'TO'),\n",
       " ('tell', 'VB'),\n",
       " ('alright', 'RB'),\n",
       " ('As', 'IN'),\n",
       " ('soar', 'NN'),\n",
       " ('wall', 'NN'),\n",
       " ('every', 'DT'),\n",
       " ('siren', 'NN'),\n",
       " ('symphony', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('tear', 'NN'),\n",
       " ('waterfall', 'NN'),\n",
       " ('Is', 'VBZ'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Oh', 'NNP'),\n",
       " ('Is', 'NNP'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Oh', 'NNP'),\n",
       " ('oh', 'MD'),\n",
       " ('oh', 'VB'),\n",
       " ('Is', 'NNP'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Is', 'VBZ'),\n",
       " ('waterfall', 'JJ'),\n",
       " ('Oh', 'NNP'),\n",
       " ('oh', 'MD'),\n",
       " ('oh', 'VB'),\n",
       " ('So', 'NNP'),\n",
       " ('hurt', 'JJ'),\n",
       " ('hurt', 'NN'),\n",
       " ('bad', 'JJ'),\n",
       " ('But', 'CC'),\n",
       " ('still', 'RB'),\n",
       " ('Ill', 'NNP'),\n",
       " ('raise', 'VB'),\n",
       " ('flag', 'NN'),\n",
       " ('Oh', 'IN'),\n",
       " ('It', 'PRP'),\n",
       " ('wa', 'VBZ'),\n",
       " ('wa', 'JJ'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'NN'),\n",
       " ('waaterfall', 'PDT'),\n",
       " ('A', 'NNP'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'NN'),\n",
       " ('wa', 'VBP'),\n",
       " ('waaterfall', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('teardrop', 'NN'),\n",
       " ('waterfall', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('teardrop', 'NN'),\n",
       " ('waterfall', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('tear', 'NN'),\n",
       " ('Every', 'NNP'),\n",
       " ('teardrop', 'NN'),\n",
       " ('waterfall', 'NN')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: use the function pos_tag of NLTK to perform POS-tagging and print the result\n",
    "tag = nltk.pos_tag(token)\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it does not return values like 'a', 'n', 'v' or 'r' as the WordNet lemmatizer is expecting...\n",
    "\n",
    "So we have to convert the values from the NLTK POS-tagging to put them into the WordNet Lemmatizer. This is done in the function *get_wordnet_pos* written below. Try to understand it, and then we will reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    output = np.asarray(pos_tag)\n",
    "    for i in range(len(pos_tag)):\n",
    "        if pos_tag[i][1].startswith('J'):\n",
    "            output[i][1] = wordnet.ADJ\n",
    "        elif pos_tag[i][1].startswith('V'):\n",
    "            output[i][1] = wordnet.VERB\n",
    "        elif pos_tag[i][1].startswith('R'):\n",
    "            output[i][1] = wordnet.ADV\n",
    "        else:\n",
    "            output[i][1] = wordnet.NOUN\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you have all we need to perform properly the lemmatization.\n",
    "\n",
    "So you have to use the following to do so:\n",
    "* your tags from the POS-tagging performed\n",
    "* the function *get_wordnet_pos*\n",
    "* the *WordNetLemmatizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I', 'n'],\n",
       "       ['turn', 'v'],\n",
       "       ['music', 'n'],\n",
       "       ['I', 'n'],\n",
       "       ['got', 'v'],\n",
       "       ['record', 'n'],\n",
       "       ['I', 'n'],\n",
       "       ['shut', 'v'],\n",
       "       ['world', 'n'],\n",
       "       ['outside', 'n'],\n",
       "       ['light', 'a'],\n",
       "       ['come', 'v'],\n",
       "       ['Maybe', 'n'],\n",
       "       ['street', 'n'],\n",
       "       ['alight', 'v'],\n",
       "       ['maybe', 'r'],\n",
       "       ['tree', 'a'],\n",
       "       ['gone', 'v'],\n",
       "       ['I', 'n'],\n",
       "       ['feel', 'v'],\n",
       "       ['heart', 'n'],\n",
       "       ['start', 'n'],\n",
       "       ['beating', 'v'],\n",
       "       ['favourite', 'n'],\n",
       "       ['song', 'n'],\n",
       "       ['And', 'n'],\n",
       "       ['kid', 'n'],\n",
       "       ['dance', 'n'],\n",
       "       ['kid', 'n'],\n",
       "       ['night', 'n'],\n",
       "       ['Until', 'n'],\n",
       "       ['Monday', 'n'],\n",
       "       ['morning', 'n'],\n",
       "       ['feel', 'n'],\n",
       "       ['another', 'n'],\n",
       "       ['life', 'n'],\n",
       "       ['I', 'n'],\n",
       "       ['turn', 'v'],\n",
       "       ['music', 'n'],\n",
       "       ['Im', 'n'],\n",
       "       ['roll', 'n'],\n",
       "       ['time', 'n'],\n",
       "       ['And', 'n'],\n",
       "       ['heaven', 'a'],\n",
       "       ['sight', 'n'],\n",
       "       ['I', 'n'],\n",
       "       ['turn', 'v'],\n",
       "       ['music', 'n'],\n",
       "       ['I', 'n'],\n",
       "       ['got', 'v'],\n",
       "       ['record', 'n'],\n",
       "       ['From', 'n'],\n",
       "       ['underneath', 'a'],\n",
       "       ['rubble', 'a'],\n",
       "       ['sing', 'v'],\n",
       "       ['rebel', 'n'],\n",
       "       ['song', 'n'],\n",
       "       ['Dont', 'n'],\n",
       "       ['want', 'n'],\n",
       "       ['see', 'n'],\n",
       "       ['another', 'n'],\n",
       "       ['generation', 'n'],\n",
       "       ['drop', 'n'],\n",
       "       ['Id', 'n'],\n",
       "       ['rather', 'r'],\n",
       "       ['comma', 'v'],\n",
       "       ['full', 'a'],\n",
       "       ['stop', 'n'],\n",
       "       ['Maybe', 'n'],\n",
       "       ['Im', 'n'],\n",
       "       ['black', 'a'],\n",
       "       ['maybe', 'r'],\n",
       "       ['Im', 'n'],\n",
       "       ['knee', 'n'],\n",
       "       ['Maybe', 'n'],\n",
       "       ['Im', 'n'],\n",
       "       ['gap', 'n'],\n",
       "       ['two', 'n'],\n",
       "       ['trapeze', 'n'],\n",
       "       ['But', 'n'],\n",
       "       ['heart', 'n'],\n",
       "       ['beating', 'n'],\n",
       "       ['pulse', 'a'],\n",
       "       ['start', 'n'],\n",
       "       ['Cathedrals', 'n'],\n",
       "       ['heart', 'n'],\n",
       "       ['As', 'n'],\n",
       "       ['saw', 'a'],\n",
       "       ['oh', 'n'],\n",
       "       ['light', 'a'],\n",
       "       ['I', 'n'],\n",
       "       ['swear', 'v'],\n",
       "       ['emerge', 'r'],\n",
       "       ['blinking', 'v'],\n",
       "       ['To', 'n'],\n",
       "       ['tell', 'v'],\n",
       "       ['alright', 'r'],\n",
       "       ['As', 'n'],\n",
       "       ['soar', 'n'],\n",
       "       ['wall', 'n'],\n",
       "       ['every', 'n'],\n",
       "       ['siren', 'n'],\n",
       "       ['symphony', 'n'],\n",
       "       ['And', 'n'],\n",
       "       ['every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['waterfall', 'n'],\n",
       "       ['Is', 'v'],\n",
       "       ['waterfall', 'a'],\n",
       "       ['Oh', 'n'],\n",
       "       ['Is', 'n'],\n",
       "       ['waterfall', 'a'],\n",
       "       ['Oh', 'n'],\n",
       "       ['oh', 'n'],\n",
       "       ['oh', 'v'],\n",
       "       ['Is', 'n'],\n",
       "       ['waterfall', 'a'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Is', 'v'],\n",
       "       ['waterfall', 'a'],\n",
       "       ['Oh', 'n'],\n",
       "       ['oh', 'n'],\n",
       "       ['oh', 'v'],\n",
       "       ['So', 'n'],\n",
       "       ['hurt', 'a'],\n",
       "       ['hurt', 'n'],\n",
       "       ['bad', 'a'],\n",
       "       ['But', 'n'],\n",
       "       ['still', 'r'],\n",
       "       ['Ill', 'n'],\n",
       "       ['raise', 'v'],\n",
       "       ['flag', 'n'],\n",
       "       ['Oh', 'n'],\n",
       "       ['It', 'n'],\n",
       "       ['wa', 'v'],\n",
       "       ['wa', 'a'],\n",
       "       ['wa', 'n'],\n",
       "       ['wa', 'n'],\n",
       "       ['waaterfall', 'n'],\n",
       "       ['A', 'n'],\n",
       "       ['wa', 'n'],\n",
       "       ['wa', 'n'],\n",
       "       ['wa', 'n'],\n",
       "       ['wa', 'v'],\n",
       "       ['waaterfall', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['teardrop', 'n'],\n",
       "       ['waterfall', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['teardrop', 'n'],\n",
       "       ['waterfall', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['tear', 'n'],\n",
       "       ['Every', 'n'],\n",
       "       ['teardrop', 'n'],\n",
       "       ['waterfall', 'n']], dtype='<U10')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform the lemmatization properly\n",
    "get_wordnet_pos(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think?\n",
    "\n",
    "Still not perfect, but it's the best we can do for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try stemming, with the help of the lecture, and see the differences compared to the lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'recor',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'ligh',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'stree',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'tree',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beat',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ki',\n",
       " 'they',\n",
       " 'dance',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ki',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morn',\n",
       " 'fee',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'th',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " '',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'recor',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 's',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Dont',\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'Id',\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'my',\n",
       " 'knee',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapeze',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " '',\n",
       " 'beat',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulse',\n",
       " 'start',\n",
       " 'Cathedra',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " '',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'th',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " 'emerge',\n",
       " 'blink',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'i',\n",
       " 'alright',\n",
       " '',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'wal',\n",
       " 'every',\n",
       " 'siren',\n",
       " '',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tea',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " '',\n",
       " 'a',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'Ill',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'w',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " '',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform stemming\n",
    "words = nltk.word_tokenize(s)\n",
    "stemmed = []\n",
    "for x in words:\n",
    "    if x[-1] == 's':\n",
    "        if x[-2] == 'e':\n",
    "            x = x[:-1]\n",
    "        else:\n",
    "            x = x[:-2]\n",
    "    elif x[-3:] == 'ing':\n",
    "        x = x[:-3]\n",
    "    stemmed.append(x)\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the difference? What would you use?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
