{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on applying similarity: Jaccard and Cosine similarity. This exercise is a simple application of the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = \"Outside the classroom, Stallman pursued his studies with even more diligence, rushing off to fulfill his laboratory-assistant duties at Rockefeller University during the week and dodging the Vietnam protesters on his way to Saturday school at Columbia. It was there, while the rest of the Science Honors Program students sat around discussing their college choices, that Stallman finally took a moment to participate in the preclass bull session.\"\n",
    "B = \"To facilitate the process, AI Lab hackers had built a system that displayed both the source and display modes on a split screen. Despite this innovative hack, switching from mode to mode was still a nuisance.\"\n",
    "C = \"With no dorm and no dancing, Stallman's social universe imploded. Like an astronaut experiencing the aftereffects of zero-gravity, Stallman found that his ability to interact with nonhackers, especially female nonhackers, had atrophied significantly. After 16 weeks in the AI Lab, the self confidence he'd been quietly accumulating during his 4 years at Harvard was virtually gone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by computing the Jaccard Similarity J of all possibilities:\n",
    "* J(A, B)\n",
    "* J(B, C)\n",
    "* J(A, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08536585365853659\n",
      "0.09210526315789473\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "# TODO: compute the Jaccard similarities\n",
    "# Split the sentences\n",
    "a = set(A.split(' '))\n",
    "b = set(B.split(' '))\n",
    "c = set(C.split(' '))\n",
    "# Compute the intersection and union\n",
    "ABI = set([x for x in a if x in b])\n",
    "ABU = set(list(a)+list(b))\n",
    "\n",
    "BCI = set([x for x in b if x in c])\n",
    "BCU = set(list(b)+list(c))\n",
    "\n",
    "ACI = set([x for x in a if x in c])\n",
    "ACU = set(list(a)+list(c))\n",
    "# Compute and print the Jaccard Similarity\n",
    "print(len(ABI)/len(ABU))\n",
    "print(len(BCI)/len(BCU))\n",
    "print(len(ACI)/len(ACU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the closest to the other according to Jaccard Similarity?\n",
    "\n",
    "Now let's do the same using TF-IDF and Cosine Similarity. Compute the TF-IDF and cosine similarities and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'and': 0.014705882352941176,\n",
       "  'around': 0.014705882352941176,\n",
       "  'assistant': 0.014705882352941176,\n",
       "  'at': 0.029411764705882353,\n",
       "  'bull': 0.014705882352941176,\n",
       "  'choices': 0.014705882352941176,\n",
       "  'classroom': 0.014705882352941176,\n",
       "  'college': 0.014705882352941176,\n",
       "  'columbia': 0.014705882352941176,\n",
       "  'diligence': 0.014705882352941176,\n",
       "  'discussing': 0.014705882352941176,\n",
       "  'dodging': 0.014705882352941176,\n",
       "  'during': 0.014705882352941176,\n",
       "  'duties': 0.014705882352941176,\n",
       "  'even': 0.014705882352941176,\n",
       "  'finally': 0.014705882352941176,\n",
       "  'fulfill': 0.014705882352941176,\n",
       "  'his': 0.04411764705882353,\n",
       "  'honors': 0.014705882352941176,\n",
       "  'in': 0.014705882352941176,\n",
       "  'it': 0.014705882352941176,\n",
       "  'laboratory': 0.014705882352941176,\n",
       "  'moment': 0.014705882352941176,\n",
       "  'more': 0.014705882352941176,\n",
       "  'of': 0.014705882352941176,\n",
       "  'off': 0.014705882352941176,\n",
       "  'on': 0.014705882352941176,\n",
       "  'outside': 0.014705882352941176,\n",
       "  'participate': 0.014705882352941176,\n",
       "  'preclass': 0.014705882352941176,\n",
       "  'program': 0.014705882352941176,\n",
       "  'protesters': 0.014705882352941176,\n",
       "  'pursued': 0.014705882352941176,\n",
       "  'rest': 0.014705882352941176,\n",
       "  'rockefeller': 0.014705882352941176,\n",
       "  'rushing': 0.014705882352941176,\n",
       "  'sat': 0.014705882352941176,\n",
       "  'saturday': 0.014705882352941176,\n",
       "  'school': 0.014705882352941176,\n",
       "  'science': 0.014705882352941176,\n",
       "  'session': 0.014705882352941176,\n",
       "  'stallman': 0.029411764705882353,\n",
       "  'students': 0.014705882352941176,\n",
       "  'studies': 0.014705882352941176,\n",
       "  'that': 0.014705882352941176,\n",
       "  'the': 0.08823529411764706,\n",
       "  'their': 0.014705882352941176,\n",
       "  'there': 0.014705882352941176,\n",
       "  'to': 0.04411764705882353,\n",
       "  'took': 0.014705882352941176,\n",
       "  'university': 0.014705882352941176,\n",
       "  'vietnam': 0.014705882352941176,\n",
       "  'was': 0.014705882352941176,\n",
       "  'way': 0.014705882352941176,\n",
       "  'week': 0.014705882352941176,\n",
       "  'while': 0.014705882352941176,\n",
       "  'with': 0.014705882352941176},\n",
       " {'ai': 0.027777777777777776,\n",
       "  'and': 0.027777777777777776,\n",
       "  'both': 0.027777777777777776,\n",
       "  'built': 0.027777777777777776,\n",
       "  'despite': 0.027777777777777776,\n",
       "  'display': 0.027777777777777776,\n",
       "  'displayed': 0.027777777777777776,\n",
       "  'facilitate': 0.027777777777777776,\n",
       "  'from': 0.027777777777777776,\n",
       "  'hack': 0.027777777777777776,\n",
       "  'hackers': 0.027777777777777776,\n",
       "  'had': 0.027777777777777776,\n",
       "  'innovative': 0.027777777777777776,\n",
       "  'lab': 0.027777777777777776,\n",
       "  'mode': 0.05555555555555555,\n",
       "  'modes': 0.027777777777777776,\n",
       "  'nuisance': 0.027777777777777776,\n",
       "  'on': 0.027777777777777776,\n",
       "  'process': 0.027777777777777776,\n",
       "  'screen': 0.027777777777777776,\n",
       "  'source': 0.027777777777777776,\n",
       "  'split': 0.027777777777777776,\n",
       "  'still': 0.027777777777777776,\n",
       "  'switching': 0.027777777777777776,\n",
       "  'system': 0.027777777777777776,\n",
       "  'that': 0.027777777777777776,\n",
       "  'the': 0.05555555555555555,\n",
       "  'this': 0.027777777777777776,\n",
       "  'to': 0.05555555555555555,\n",
       "  'was': 0.027777777777777776},\n",
       " {'16': 0.017857142857142856,\n",
       "  'ability': 0.017857142857142856,\n",
       "  'accumulating': 0.017857142857142856,\n",
       "  'after': 0.017857142857142856,\n",
       "  'aftereffects': 0.017857142857142856,\n",
       "  'ai': 0.017857142857142856,\n",
       "  'an': 0.017857142857142856,\n",
       "  'and': 0.017857142857142856,\n",
       "  'astronaut': 0.017857142857142856,\n",
       "  'at': 0.017857142857142856,\n",
       "  'atrophied': 0.017857142857142856,\n",
       "  'been': 0.017857142857142856,\n",
       "  'confidence': 0.017857142857142856,\n",
       "  'dancing': 0.017857142857142856,\n",
       "  'dorm': 0.017857142857142856,\n",
       "  'during': 0.017857142857142856,\n",
       "  'especially': 0.017857142857142856,\n",
       "  'experiencing': 0.017857142857142856,\n",
       "  'female': 0.017857142857142856,\n",
       "  'found': 0.017857142857142856,\n",
       "  'gone': 0.017857142857142856,\n",
       "  'gravity': 0.017857142857142856,\n",
       "  'had': 0.017857142857142856,\n",
       "  'harvard': 0.017857142857142856,\n",
       "  'he': 0.017857142857142856,\n",
       "  'his': 0.03571428571428571,\n",
       "  'imploded': 0.017857142857142856,\n",
       "  'in': 0.017857142857142856,\n",
       "  'interact': 0.017857142857142856,\n",
       "  'lab': 0.017857142857142856,\n",
       "  'like': 0.017857142857142856,\n",
       "  'no': 0.03571428571428571,\n",
       "  'nonhackers': 0.03571428571428571,\n",
       "  'of': 0.017857142857142856,\n",
       "  'quietly': 0.017857142857142856,\n",
       "  'self': 0.017857142857142856,\n",
       "  'significantly': 0.017857142857142856,\n",
       "  'social': 0.017857142857142856,\n",
       "  'stallman': 0.03571428571428571,\n",
       "  'that': 0.017857142857142856,\n",
       "  'the': 0.05357142857142857,\n",
       "  'to': 0.017857142857142856,\n",
       "  'universe': 0.017857142857142856,\n",
       "  'virtually': 0.017857142857142856,\n",
       "  'was': 0.017857142857142856,\n",
       "  'weeks': 0.017857142857142856,\n",
       "  'with': 0.03571428571428571,\n",
       "  'years': 0.017857142857142856,\n",
       "  'zero': 0.017857142857142856}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vec = vectorizer.fit_transform([A])\n",
    "avec = vec.toarray()\n",
    "aname = vectorizer.get_feature_names_out()\n",
    "vec = vectorizer.fit_transform([B])\n",
    "bvec = vec.toarray()\n",
    "bname = vectorizer.get_feature_names_out()\n",
    "vec = vectorizer.fit_transform([C])\n",
    "cvec = vec.toarray()\n",
    "cname = vectorizer.get_feature_names_out()\n",
    "\n",
    "adict = {}\n",
    "bdict = {}\n",
    "cdict = {}\n",
    "for x,y in zip(aname,avec[0]):\n",
    "    adict[x] = y/len(A.split(' '))\n",
    "for x,y in zip(bname,bvec[0]):\n",
    "    bdict[x] = y/len(B.split(' '))\n",
    "for x,y in zip(cname,cvec[0]):\n",
    "    cdict[x] = y/len(C.split(' '))\n",
    "\n",
    "tf = [adict,bdict,cdict]\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dancing': 2.09861228866811,\n",
       " 'he': 2.09861228866811,\n",
       " 'there': 2.09861228866811,\n",
       " 'with': 1.4054651081081644,\n",
       " 'aftereffects': 2.09861228866811,\n",
       " 'vietnam': 2.09861228866811,\n",
       " 'that': 1.0,\n",
       " 'at': 1.4054651081081644,\n",
       " 'hack': 2.09861228866811,\n",
       " 'self': 2.09861228866811,\n",
       " 'virtually': 2.09861228866811,\n",
       " 'nonhackers': 2.09861228866811,\n",
       " '16': 2.09861228866811,\n",
       " 'duties': 2.09861228866811,\n",
       " 'no': 2.09861228866811,\n",
       " 'on': 1.4054651081081644,\n",
       " 'stallman': 1.4054651081081644,\n",
       " 'his': 1.4054651081081644,\n",
       " 'process': 2.09861228866811,\n",
       " 'universe': 2.09861228866811,\n",
       " 'in': 1.4054651081081644,\n",
       " 'displayed': 2.09861228866811,\n",
       " 'both': 2.09861228866811,\n",
       " 'diligence': 2.09861228866811,\n",
       " 'assistant': 2.09861228866811,\n",
       " 'especially': 2.09861228866811,\n",
       " 'honors': 2.09861228866811,\n",
       " 'quietly': 2.09861228866811,\n",
       " 'college': 2.09861228866811,\n",
       " 'studies': 2.09861228866811,\n",
       " 'significantly': 2.09861228866811,\n",
       " 'around': 2.09861228866811,\n",
       " 'students': 2.09861228866811,\n",
       " 'split': 2.09861228866811,\n",
       " 'choices': 2.09861228866811,\n",
       " 'gone': 2.09861228866811,\n",
       " 'preclass': 2.09861228866811,\n",
       " 'mode': 2.09861228866811,\n",
       " 'weeks': 2.09861228866811,\n",
       " 'ai': 1.4054651081081644,\n",
       " 'of': 1.4054651081081644,\n",
       " 'university': 2.09861228866811,\n",
       " 'facilitate': 2.09861228866811,\n",
       " 'system': 2.09861228866811,\n",
       " 'accumulating': 2.09861228866811,\n",
       " 'modes': 2.09861228866811,\n",
       " 'during': 1.4054651081081644,\n",
       " 'lab': 1.4054651081081644,\n",
       " 'had': 1.4054651081081644,\n",
       " 'while': 2.09861228866811,\n",
       " 'dodging': 2.09861228866811,\n",
       " 'week': 2.09861228866811,\n",
       " 'screen': 2.09861228866811,\n",
       " 'pursued': 2.09861228866811,\n",
       " 'built': 2.09861228866811,\n",
       " 'saturday': 2.09861228866811,\n",
       " 'moment': 2.09861228866811,\n",
       " 'protesters': 2.09861228866811,\n",
       " 'classroom': 2.09861228866811,\n",
       " 'rest': 2.09861228866811,\n",
       " 'interact': 2.09861228866811,\n",
       " 'rushing': 2.09861228866811,\n",
       " 'harvard': 2.09861228866811,\n",
       " 'more': 2.09861228866811,\n",
       " 'like': 2.09861228866811,\n",
       " 'from': 2.09861228866811,\n",
       " 'way': 2.09861228866811,\n",
       " 'hackers': 2.09861228866811,\n",
       " 'rockefeller': 2.09861228866811,\n",
       " 'display': 2.09861228866811,\n",
       " 'ability': 2.09861228866811,\n",
       " 'off': 2.09861228866811,\n",
       " 'astronaut': 2.09861228866811,\n",
       " 'even': 2.09861228866811,\n",
       " 'school': 2.09861228866811,\n",
       " 'took': 2.09861228866811,\n",
       " 'innovative': 2.09861228866811,\n",
       " 'social': 2.09861228866811,\n",
       " 'program': 2.09861228866811,\n",
       " 'nuisance': 2.09861228866811,\n",
       " 'imploded': 2.09861228866811,\n",
       " 'found': 2.09861228866811,\n",
       " 'years': 2.09861228866811,\n",
       " 'finally': 2.09861228866811,\n",
       " 'after': 2.09861228866811,\n",
       " 'laboratory': 2.09861228866811,\n",
       " 'confidence': 2.09861228866811,\n",
       " 'participate': 2.09861228866811,\n",
       " 'the': 1.0,\n",
       " 'bull': 2.09861228866811,\n",
       " 'discussing': 2.09861228866811,\n",
       " 'dorm': 2.09861228866811,\n",
       " 'experiencing': 2.09861228866811,\n",
       " 'to': 1.0,\n",
       " 'gravity': 2.09861228866811,\n",
       " 'it': 2.09861228866811,\n",
       " 'was': 1.0,\n",
       " 'columbia': 2.09861228866811,\n",
       " 'sat': 2.09861228866811,\n",
       " 'session': 2.09861228866811,\n",
       " 'and': 1.0,\n",
       " 'this': 2.09861228866811,\n",
       " 'been': 2.09861228866811,\n",
       " 'zero': 2.09861228866811,\n",
       " 'outside': 2.09861228866811,\n",
       " 'still': 2.09861228866811,\n",
       " 'fulfill': 2.09861228866811,\n",
       " 'their': 2.09861228866811,\n",
       " 'source': 2.09861228866811,\n",
       " 'switching': 2.09861228866811,\n",
       " 'despite': 2.09861228866811,\n",
       " 'atrophied': 2.09861228866811,\n",
       " 'science': 2.09861228866811,\n",
       " 'an': 2.09861228866811,\n",
       " 'female': 2.09861228866811}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfi = {}\n",
    "for x in set([*adict,*bdict,*cdict]):\n",
    "    ci = 0\n",
    "    if x in adict:\n",
    "        ci += 1\n",
    "    if x in bdict:\n",
    "        ci += 1\n",
    "    if x in cdict:\n",
    "        ci += 1\n",
    "    tfi[x] = 1+math.log(3/ci)\n",
    "tfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ai': 0.03904069744744901,\n",
       "  'and': 0.027777777777777776,\n",
       "  'both': 0.05829478579633639,\n",
       "  'built': 0.05829478579633639,\n",
       "  'despite': 0.05829478579633639,\n",
       "  'display': 0.05829478579633639,\n",
       "  'displayed': 0.05829478579633639,\n",
       "  'facilitate': 0.05829478579633639,\n",
       "  'from': 0.05829478579633639,\n",
       "  'hack': 0.05829478579633639,\n",
       "  'hackers': 0.05829478579633639,\n",
       "  'had': 0.03904069744744901,\n",
       "  'innovative': 0.05829478579633639,\n",
       "  'lab': 0.03904069744744901,\n",
       "  'mode': 0.11658957159267277,\n",
       "  'modes': 0.05829478579633639,\n",
       "  'nuisance': 0.05829478579633639,\n",
       "  'on': 0.03904069744744901,\n",
       "  'process': 0.05829478579633639,\n",
       "  'screen': 0.05829478579633639,\n",
       "  'source': 0.05829478579633639,\n",
       "  'split': 0.05829478579633639,\n",
       "  'still': 0.05829478579633639,\n",
       "  'switching': 0.05829478579633639,\n",
       "  'system': 0.05829478579633639,\n",
       "  'that': 0.027777777777777776,\n",
       "  'the': 0.05555555555555555,\n",
       "  'this': 0.05829478579633639,\n",
       "  'to': 0.05555555555555555,\n",
       "  'was': 0.027777777777777776},\n",
       " {'16': 0.037475219440501965,\n",
       "  'ability': 0.037475219440501965,\n",
       "  'accumulating': 0.037475219440501965,\n",
       "  'after': 0.037475219440501965,\n",
       "  'aftereffects': 0.037475219440501965,\n",
       "  'ai': 0.02509759121621722,\n",
       "  'an': 0.037475219440501965,\n",
       "  'and': 0.017857142857142856,\n",
       "  'astronaut': 0.037475219440501965,\n",
       "  'at': 0.02509759121621722,\n",
       "  'atrophied': 0.037475219440501965,\n",
       "  'been': 0.037475219440501965,\n",
       "  'confidence': 0.037475219440501965,\n",
       "  'dancing': 0.037475219440501965,\n",
       "  'dorm': 0.037475219440501965,\n",
       "  'during': 0.02509759121621722,\n",
       "  'especially': 0.037475219440501965,\n",
       "  'experiencing': 0.037475219440501965,\n",
       "  'female': 0.037475219440501965,\n",
       "  'found': 0.037475219440501965,\n",
       "  'gone': 0.037475219440501965,\n",
       "  'gravity': 0.037475219440501965,\n",
       "  'had': 0.02509759121621722,\n",
       "  'harvard': 0.037475219440501965,\n",
       "  'he': 0.037475219440501965,\n",
       "  'his': 0.05019518243243444,\n",
       "  'imploded': 0.037475219440501965,\n",
       "  'in': 0.02509759121621722,\n",
       "  'interact': 0.037475219440501965,\n",
       "  'lab': 0.02509759121621722,\n",
       "  'like': 0.037475219440501965,\n",
       "  'no': 0.07495043888100393,\n",
       "  'nonhackers': 0.07495043888100393,\n",
       "  'of': 0.02509759121621722,\n",
       "  'quietly': 0.037475219440501965,\n",
       "  'self': 0.037475219440501965,\n",
       "  'significantly': 0.037475219440501965,\n",
       "  'social': 0.037475219440501965,\n",
       "  'stallman': 0.05019518243243444,\n",
       "  'that': 0.017857142857142856,\n",
       "  'the': 0.05357142857142857,\n",
       "  'to': 0.017857142857142856,\n",
       "  'universe': 0.037475219440501965,\n",
       "  'virtually': 0.037475219440501965,\n",
       "  'was': 0.017857142857142856,\n",
       "  'weeks': 0.037475219440501965,\n",
       "  'with': 0.05019518243243444,\n",
       "  'years': 0.037475219440501965,\n",
       "  'zero': 0.037475219440501965},\n",
       " {'and': 0.014705882352941176,\n",
       "  'around': 0.03086194542158985,\n",
       "  'assistant': 0.03086194542158985,\n",
       "  'at': 0.04133720906200483,\n",
       "  'bull': 0.03086194542158985,\n",
       "  'choices': 0.03086194542158985,\n",
       "  'classroom': 0.03086194542158985,\n",
       "  'college': 0.03086194542158985,\n",
       "  'columbia': 0.03086194542158985,\n",
       "  'diligence': 0.03086194542158985,\n",
       "  'discussing': 0.03086194542158985,\n",
       "  'dodging': 0.03086194542158985,\n",
       "  'during': 0.020668604531002416,\n",
       "  'duties': 0.03086194542158985,\n",
       "  'even': 0.03086194542158985,\n",
       "  'finally': 0.03086194542158985,\n",
       "  'fulfill': 0.03086194542158985,\n",
       "  'his': 0.062005813593007254,\n",
       "  'honors': 0.03086194542158985,\n",
       "  'in': 0.020668604531002416,\n",
       "  'it': 0.03086194542158985,\n",
       "  'laboratory': 0.03086194542158985,\n",
       "  'moment': 0.03086194542158985,\n",
       "  'more': 0.03086194542158985,\n",
       "  'of': 0.020668604531002416,\n",
       "  'off': 0.03086194542158985,\n",
       "  'on': 0.020668604531002416,\n",
       "  'outside': 0.03086194542158985,\n",
       "  'participate': 0.03086194542158985,\n",
       "  'preclass': 0.03086194542158985,\n",
       "  'program': 0.03086194542158985,\n",
       "  'protesters': 0.03086194542158985,\n",
       "  'pursued': 0.03086194542158985,\n",
       "  'rest': 0.03086194542158985,\n",
       "  'rockefeller': 0.03086194542158985,\n",
       "  'rushing': 0.03086194542158985,\n",
       "  'sat': 0.03086194542158985,\n",
       "  'saturday': 0.03086194542158985,\n",
       "  'school': 0.03086194542158985,\n",
       "  'science': 0.03086194542158985,\n",
       "  'session': 0.03086194542158985,\n",
       "  'stallman': 0.04133720906200483,\n",
       "  'students': 0.03086194542158985,\n",
       "  'studies': 0.03086194542158985,\n",
       "  'that': 0.014705882352941176,\n",
       "  'the': 0.08823529411764706,\n",
       "  'their': 0.03086194542158985,\n",
       "  'there': 0.03086194542158985,\n",
       "  'to': 0.04411764705882353,\n",
       "  'took': 0.03086194542158985,\n",
       "  'university': 0.03086194542158985,\n",
       "  'vietnam': 0.03086194542158985,\n",
       "  'was': 0.014705882352941176,\n",
       "  'way': 0.03086194542158985,\n",
       "  'week': 0.03086194542158985,\n",
       "  'while': 0.03086194542158985,\n",
       "  'with': 0.020668604531002416}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = [{},{},{}]\n",
    "for e,y in enumerate(tf):\n",
    "    for x in y:\n",
    "        tfidf[e-1][x] = y[x]*tfi[x]\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos(A, B): [[0.1679327]]\n",
      "cos(B, C): [[0.13618963]]\n",
      "cos(A, C): [[0.2850296]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: compute the TF-IDF of A, B and C and the cosine similarities of all possibilities\n",
    "\n",
    "# could only find examples of finding similarity based on a particular query rather than one document to another\n",
    "# where cos(A,b) =/= cos(B,A)\n",
    "\n",
    "# given values are similar quallitatively except for (B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it consistent with the Jaccard values?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
